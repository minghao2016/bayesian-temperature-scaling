# Well-calibrated Model Uncertainty with Temperature Scaling for Dropout Variational Inference

Max-Heinrich Laves, Sontje Ihler, Karl-Philipp Kortmann, Tobias Ortmaier

## Abstract

In this paper, well-calibrated model uncertainty is obtained by using
temperature scaling together with Monte Carlo dropout as approximation to
Bayesian inference. The proposed approach can easily be derived from frequentist
temperature scaling and yields better calibrated model uncertainty as well as
softmax likelihood.

Submitted to NeurIPS Bayesian Deep Learning Workshop 2019.
